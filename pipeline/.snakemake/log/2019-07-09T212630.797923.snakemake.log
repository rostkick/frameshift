Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	cdhit_filter
	1	get_frame_shifts
	1	get_intersected_prot
	1	get_orf
	4

[Tue Jul  9 21:26:30 2019]
rule get_orf:
    input: data/Sclerotinia_sclerotiorum.ASM14694v1.dna.toplevel.fa
    output: data/Scler_predicted_orfs.fasta
    jobid: 3

[Tue Jul  9 21:26:33 2019]
Finished job 3.
1 of 4 steps (25%) done

[Tue Jul  9 21:26:33 2019]
rule get_frame_shifts:
    input: data/Scler_predicted_orfs.fasta, data/Sclerotinia_sclerotiorum.ASM14694v1.dna.toplevel.fa
    output: data/Scler_{prms.min_orf_length}_{prms.min_int_length}.txt
    jobid: 2

Terminating processes on user request, this might take some time.
Complete log: /home/rskick/Projects/amyl/frame_shift_func/frameshift/pipeline/.snakemake/log/2019-07-09T212630.797923.snakemake.log
