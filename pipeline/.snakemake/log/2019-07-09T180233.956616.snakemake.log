Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	get_frame_shifts
	1	get_orf
	2

[Tue Jul  9 18:02:33 2019]
rule get_orf:
    input: Sclerotinia_sclerotiorum.ASM14694v1.dna.toplevel.fa
    output: Scler_predicted_orfs.fasta
    jobid: 1

[Tue Jul  9 18:02:36 2019]
Finished job 1.
1 of 2 steps (50%) done

[Tue Jul  9 18:02:36 2019]
rule get_frame_shifts:
    input: Scler_predicted_orfs.fasta, Sclerotinia_sclerotiorum.ASM14694v1.dna.toplevel.fa
    output: Scler_300_100.txt
    jobid: 0

[Tue Jul  9 18:02:36 2019]
Error in rule get_frame_shifts:
    jobid: 0
    output: Scler_300_100.txt
    shell:
        python3 Frshft_FINDER.py -input_dna Scler_predicted_orfs.fasta -input_genome Sclerotinia_sclerotiorum.ASM14694v1.dna.toplevel.fa -min_orf 300 -intreval_length 100 -output Scler_300_100.txt
        (exited with non-zero exit code)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/rskick/Projects/amyl/frame_shift_func/frameshift/pipeline/.snakemake/log/2019-07-09T180233.956616.snakemake.log
